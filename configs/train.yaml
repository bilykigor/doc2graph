batch_size: 128
batch_size_step: 128
epoch_size_step: 100
epochs: 10
lr: 1e-3
weight_decay: 1e-4
val_size : 0.1
optimizer: Adam # or AdamW, SGD - NOT YET IMPLEMENTED
scheduler:
  - ReduceLROnPlateau # CosineAnnealingLR, None- NOT YET IMPLEMENTED
stopper_metric: loss #acc # loss or acc
seed: 42
verbose: 0
